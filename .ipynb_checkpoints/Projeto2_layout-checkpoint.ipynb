{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Luiz Felipe Domingues Valente\n",
    "\n",
    "Nome: Jo√£o Guilherme Cintra de Freitas Almeida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @jofenina\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "# with open('auth.pass') as fp:    \n",
    "#     data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'snickers'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#     msgs.append(msg.full_text.lower())\n",
    "#     i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tiagoatoc nunca pensei que me mandasses comer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credo q eu acordei sem paci√™ncia, e j√° to come...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samyra me deu batata frita com cheddar e bacon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crlh acabei de descobrir q tem sorvete de snic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@yenexiel ningu√©m compra snickers pra mim quan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  @tiagoatoc nunca pensei que me mandasses comer...           0\n",
       "1  credo q eu acordei sem paci√™ncia, e j√° to come...           0\n",
       "2  samyra me deu batata frita com cheddar e bacon...           1\n",
       "3  crlh acabei de descobrir q tem sorvete de snic...           1\n",
       "4  @yenexiel ningu√©m compra snickers pra mim quan...           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tr = pd.read_excel(\"snickers.xlsx\")\n",
    "tweets_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @tiagoatoc nunca pensei que me mandasses comer...\n",
       "1    credo q eu acordei sem paci√™ncia, e j√° to come...\n",
       "2    samyra me deu batata frita com cheddar e bacon...\n",
       "3    crlh acabei de descobrir q tem sorvete de snic...\n",
       "4    @yenexiel ningu√©m compra snickers pra mim quan...\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = tweets_tr.loc[:, \"Treinamento\"]\n",
    "teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \n",
    "#  Limpeza de caracteres\n",
    "\n",
    "    punctuation = '[!\\-.:?;@]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiagoatoc nunca pensei que me mandasses comer snickers antes de dormir sinceramente',\n",
       " 'credo q eu acordei sem paci√™ncia, e j√° to comendo um snickers de caf√© da manh√£',\n",
       " 'samyra me deu batata frita com cheddar e bacon, e evelyn me deu snickers, amo minhas amigas',\n",
       " 'crlh acabei de descobrir q tem sorvete de snickers eu preciso pra ontem',\n",
       " 'yenexiel ningu√©m compra snickers pra mim quando t√¥ triste']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_limpos1 = []\n",
    "t_limpos2 = []\n",
    "t_limpos = []\n",
    "for linha in teste:\n",
    "    b=linha.lower()\n",
    "    t_limpos1.append(cleanup(b))\n",
    "for e in t_limpos1:\n",
    "    a = e.strip()\n",
    "    t_limpos2.append(a)\n",
    "for s in t_limpos2:\n",
    "    z = ' '.join(s.split())\n",
    "    t_limpos.append(z)\n",
    "t_limpos[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          tiagoatoc\n",
       "1              nunca\n",
       "2             pensei\n",
       "3                que\n",
       "4                 me\n",
       "5          mandasses\n",
       "6              comer\n",
       "7           snickers\n",
       "8              antes\n",
       "9                 de\n",
       "10            dormir\n",
       "11      sinceramente\n",
       "12             credo\n",
       "13                 q\n",
       "14                eu\n",
       "15           acordei\n",
       "16               sem\n",
       "17        paci√™ncia,\n",
       "18                 e\n",
       "19                j√°\n",
       "20                to\n",
       "21           comendo\n",
       "22                um\n",
       "23          snickers\n",
       "24                de\n",
       "25              caf√©\n",
       "26                da\n",
       "27             manh√£\n",
       "28            samyra\n",
       "29                me\n",
       "            ...     \n",
       "4417              de\n",
       "4418        presente\n",
       "4419           estou\n",
       "4420           feliz\n",
       "4421              rt\n",
       "4422      papi_fabii\n",
       "4423               1\n",
       "4424          pacote\n",
       "4425              de\n",
       "4426          gomas,\n",
       "4427               1\n",
       "4428          pacote\n",
       "4429              de\n",
       "4430      rebu√ßados,\n",
       "4431               1\n",
       "4432          pacote\n",
       "4433              de\n",
       "4434        snickers\n",
       "4435               e\n",
       "4436            mais\n",
       "4437              de\n",
       "4438             100\n",
       "4439         motivos\n",
       "4440          porque\n",
       "4441              te\n",
       "4442             amo\n",
       "4443           foram\n",
       "4444        precisos\n",
       "4445           menos\n",
       "4446             de‚Ä¶\n",
       "Length: 4447, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_tweets = ' '.join(t_limpos)\n",
    "a = pd.Series(serie_tweets.split())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers         267\n",
       "de               143\n",
       "e                119\n",
       "um               107\n",
       "eu                99\n",
       "do                77\n",
       "o                 74\n",
       "que               71\n",
       "a                 64\n",
       "√©                 60\n",
       "mais              57\n",
       "da                52\n",
       "n√£o               47\n",
       "pra               47\n",
       "rt                45\n",
       "no                44\n",
       "me                43\n",
       "propaganda        39\n",
       "com               38\n",
       "https             33\n",
       "//t               33\n",
       "uma               33\n",
       "s√≥                31\n",
       "q                 30\n",
       "1                 25\n",
       "aguento           25\n",
       "youtube           24\n",
       "essa              24\n",
       "em                24\n",
       "minha             23\n",
       "                ... \n",
       "sagu               1\n",
       "exaltei            1\n",
       "sdds               1\n",
       "empada             1\n",
       "ia                 1\n",
       "pobre              1\n",
       "‚ù§                  1\n",
       "wwwmlna            1\n",
       "ideia              1\n",
       "perdendo           1\n",
       "amor,              1\n",
       "d3isiane           1\n",
       "costumo            1\n",
       "autistas           1\n",
       "saber              1\n",
       "tao                1\n",
       "fav                1\n",
       "t√™m                1\n",
       "desempregada       1\n",
       "corta              1\n",
       "jmiranda810        1\n",
       "ü•¥ü•¥ü•¥üòîüíï              1\n",
       "biscoito           1\n",
       "interrompida       1\n",
       "suco               1\n",
       "rottenbaby666      1\n",
       "algumas            1\n",
       "catsant0s          1\n",
       "socorroooo         1\n",
       "ferrero            1\n",
       "Length: 1351, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers         0.060040\n",
       "de               0.032157\n",
       "e                0.026760\n",
       "um               0.024061\n",
       "eu               0.022262\n",
       "do               0.017315\n",
       "o                0.016640\n",
       "que              0.015966\n",
       "a                0.014392\n",
       "√©                0.013492\n",
       "mais             0.012818\n",
       "da               0.011693\n",
       "n√£o              0.010569\n",
       "pra              0.010569\n",
       "rt               0.010119\n",
       "no               0.009894\n",
       "me               0.009669\n",
       "propaganda       0.008770\n",
       "com              0.008545\n",
       "https            0.007421\n",
       "//t              0.007421\n",
       "uma              0.007421\n",
       "s√≥               0.006971\n",
       "q                0.006746\n",
       "1                0.005622\n",
       "aguento          0.005622\n",
       "youtube          0.005397\n",
       "essa             0.005397\n",
       "em               0.005397\n",
       "minha            0.005172\n",
       "                   ...   \n",
       "sagu             0.000225\n",
       "exaltei          0.000225\n",
       "sdds             0.000225\n",
       "empada           0.000225\n",
       "ia               0.000225\n",
       "pobre            0.000225\n",
       "‚ù§                0.000225\n",
       "wwwmlna          0.000225\n",
       "ideia            0.000225\n",
       "perdendo         0.000225\n",
       "amor,            0.000225\n",
       "d3isiane         0.000225\n",
       "costumo          0.000225\n",
       "autistas         0.000225\n",
       "saber            0.000225\n",
       "tao              0.000225\n",
       "fav              0.000225\n",
       "t√™m              0.000225\n",
       "desempregada     0.000225\n",
       "corta            0.000225\n",
       "jmiranda810      0.000225\n",
       "ü•¥ü•¥ü•¥üòîüíï            0.000225\n",
       "biscoito         0.000225\n",
       "interrompida     0.000225\n",
       "suco             0.000225\n",
       "rottenbaby666    0.000225\n",
       "algumas          0.000225\n",
       "catsant0s        0.000225\n",
       "socorroooo       0.000225\n",
       "ferrero          0.000225\n",
       "Length: 1351, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_tweets_relativa = a.value_counts(True)\n",
    "tabela_tweets_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06004047672588262\n",
      "0.032156510006746124\n",
      "0.026759613222397123\n",
      "0.024061164830222623\n"
     ]
    }
   ],
   "source": [
    "imprime = 4\n",
    "for palavra in tabela_tweets_relativa.index:\n",
    "    if imprime:\n",
    "        print(tabela_tweets_relativa[palavra])\n",
    "        imprime-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

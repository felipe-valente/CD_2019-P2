{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Luiz Felipe Domingues Valente\n",
    "\n",
    "Nome: Jo√£o Guilherme Cintra de Freitas Almeida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import re \n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***[Preencha aqui o id da sua conta. Ex: @fulano ]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "# Coloque aqui o identificador da conta no twitter: @jofenina\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "# with open('auth.pass') as fp:    \n",
    "#     data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "# auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "# auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'snickers'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#     msgs.append(msg.full_text.lower())\n",
    "#     i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tiagoatoc nunca pensei que me mandasses comer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credo q eu acordei sem paci√™ncia, e j√° to come...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samyra me deu batata frita com cheddar e bacon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crlh acabei de descobrir q tem sorvete de snic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@yenexiel ningu√©m compra snickers pra mim quan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  @tiagoatoc nunca pensei que me mandasses comer...           0\n",
       "1  credo q eu acordei sem paci√™ncia, e j√° to come...           0\n",
       "2  samyra me deu batata frita com cheddar e bacon...           1\n",
       "3  crlh acabei de descobrir q tem sorvete de snic...           1\n",
       "4  @yenexiel ningu√©m compra snickers pra mim quan...           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tr_sujos = pd.read_excel(\"snickers.xlsx\", sheet_name = \"Treinamento\")\n",
    "tweets_tr_sujos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @tiagoatoc nunca pensei que me mandasses comer...\n",
       "1    credo q eu acordei sem paci√™ncia, e j√° to come...\n",
       "2    samyra me deu batata frita com cheddar e bacon...\n",
       "3    crlh acabei de descobrir q tem sorvete de snic...\n",
       "4    @yenexiel ningu√©m compra snickers pra mim quan...\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treinamento = tweets_tr_sujos.loc[:, \"Treinamento\"]\n",
    "rel=tweets_tr_sujos.loc[:, \"Relev√¢ncia\"]\n",
    "treinamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(text):\n",
    "    \n",
    "#  Limpeza de caracteres\n",
    "\n",
    "    punctuation = '[!\\-.:?;@#$%&*_1234567890]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiagoatoc nunca pensei que me mandasses comer snickers antes de dormir sinceramente',\n",
       " 'credo q eu acordei sem paci√™ncia, e j√° to comendo um snickers de caf√© da manh√£',\n",
       " 'samyra me deu batata frita com cheddar e bacon, e evelyn me deu snickers, amo minhas amigas',\n",
       " 'crlh acabei de descobrir q tem sorvete de snickers eu preciso pra ontem',\n",
       " 'yenexiel ningu√©m compra snickers pra mim quando t√¥ triste']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_limpos1 = []\n",
    "t_limpos2 = []\n",
    "t_limpos = []\n",
    "for linha in treinamento:\n",
    "    b=linha.lower()\n",
    "    t_limpos1.append(cleanup(b))\n",
    "for e in t_limpos1:\n",
    "    a = e.strip()\n",
    "    t_limpos2.append(a)\n",
    "for s in t_limpos2:\n",
    "    z = ' '.join(s.split())\n",
    "    t_limpos.append(z)\n",
    "t_limpos[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espa√ßa emoji e texto limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search your emoji\n",
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n",
    "\n",
    "results=[add_space(text) for text in t_limpos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_palavras = []\n",
    "for pepe in results:\n",
    "    lista_palavras += pepe.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers    0.060292\n",
       "de          0.031581\n",
       "e           0.026281\n",
       "um          0.023631\n",
       "eu          0.021864\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = pd.Series(lista_palavras)\n",
    "p_palavras = banana.value_counts(True)\n",
    "p_palavras.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabela com limpeza e relev√¢ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiagoatoc nunca pensei que me mandasses comer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credo q eu acordei sem paci√™ncia, e j√° to come...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samyra me deu batata frita com cheddar e bacon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crlh acabei de descobrir q tem sorvete de snic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yenexiel ningu√©m compra snickers pra mim quand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  tiagoatoc nunca pensei que me mandasses comer ...           0\n",
       "1  credo q eu acordei sem paci√™ncia, e j√° to come...           0\n",
       "2  samyra me deu batata frita com cheddar e bacon...           1\n",
       "3  crlh acabei de descobrir q tem sorvete de snic...           1\n",
       "4  yenexiel ningu√©m compra snickers pra mim quand...           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_tr = pd.DataFrame({\"Treinamento\": results,\"Relev√¢ncia\": rel})\n",
    "t_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Relevantes Limpos e frequ√™ncia de suas Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samyra me deu batata frita com cheddar e bacon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crlh acabei de descobrir q tem sorvete de snic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rt thaii xx s√©rio, o an√∫ncio da snickers no yt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt amandinhavr eu esperando a propaganda insup...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n√£o aguento mais esses an√∫ncios da snickers, n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "2  samyra me deu batata frita com cheddar e bacon...           1\n",
       "3  crlh acabei de descobrir q tem sorvete de snic...           1\n",
       "6  rt thaii xx s√©rio, o an√∫ncio da snickers no yt...           1\n",
       "7  rt amandinhavr eu esperando a propaganda insup...           1\n",
       "8  n√£o aguento mais esses an√∫ncios da snickers, n...           1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rel= t_tr[(t_tr.Relev√¢ncia==1)]\n",
    "t_rel.head()\n",
    "len(t_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    samyra\n",
       "1        me\n",
       "2       deu\n",
       "3    batata\n",
       "4     frita\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_tweets = ' '.join(t_rel.loc[:,\"Treinamento\"])\n",
    "a = pd.Series(serie_tweets.split())\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers    166\n",
       "de           92\n",
       "eu           69\n",
       "do           62\n",
       "e            55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_tweets_relativar = a.value_counts()\n",
    "tabela_tweets_relativar[\"gosto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733333333333334"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4266666666666667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidade de o tweet ser relevante:\n",
    "prob_t_relevante = 172/300\n",
    "prob_t_relevante\n",
    "# Probabilidade de o tweet ser irrelevante:\n",
    "prob_t_irrelevante = 128/300\n",
    "prob_t_irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers    0.036661\n",
       "de          0.020318\n",
       "eu          0.015239\n",
       "do          0.013693\n",
       "e           0.012147\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "snickers    0.023631\n",
       "e           0.014134\n",
       "um          0.011926\n",
       "de          0.011263\n",
       "o           0.008834\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_palavra_relevante = tabela_tweets_relativar / len(lista_palavras)\n",
    "prob_palavra_relevante.head()\n",
    "prob_palavra_irrelevante = tabela_tweets_relativa_n_rel / len(lista_palavras)\n",
    "prob_palavra_irrelevante.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log=[]\n",
    "# freq_log=0\n",
    "# for numero in p_palavras:\n",
    "#     freq_log = np.log10(numero)\n",
    "#     print(freq_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log=[]\n",
    "# for frase in t_rel.Treinamento:\n",
    "#     frase_d=frase.split()\n",
    "#     freq_log = 0 \n",
    "#     for palavra in frase_d:\n",
    "#         if palavra in p_palavras:\n",
    "#             freq_log += np.log10(p_palavras[palavra])\n",
    "#             log.append(freq_log)\n",
    "# log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets n√£o Relevantes Limpos e frequ√™ncia de suas Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "t_n_rel= t_tr[(t_tr.Relev√¢ncia==0)]\n",
    "print(len(t_n_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    samyra\n",
       "1        me\n",
       "2       deu\n",
       "3    batata\n",
       "4     frita\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_tweets_n_rel = ' '.join(t_n_rel.loc[:,\"Treinamento\"])\n",
    "a_n_rel = pd.Series(serie_tweets_n_rel.split())\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers    107\n",
       "e            64\n",
       "um           54\n",
       "de           51\n",
       "o            40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_n_rel.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snickers    107\n",
       "e            64\n",
       "um           54\n",
       "de           51\n",
       "o            40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequencia que a palavra aparece dentro dos irrelevantes\n",
    "tabela_tweets_relativa_n_rel = a_n_rel.value_counts()\n",
    "tabela_tweets_relativa_n_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic_log = {}\n",
    "# for frase in t_tr.Treinamento:\n",
    "#     frase_d=frase.split()\n",
    "#     freq_log = 0 \n",
    "#     for palavra in frase_d:\n",
    "#         if palavra in p_palavras:\n",
    "#             freq_log += np.log10(p_palavras[palavra])\n",
    "#     dic_log[frase] = freq_log\n",
    "# dic_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frase n relevante\n"
     ]
    }
   ],
   "source": [
    "def classificador(tweet):\n",
    "    lista_result_num = []\n",
    "    palavras = tweet.split()\n",
    "    prob=0\n",
    "    prob_n=0\n",
    "    log  = 0\n",
    "    for p in lista_palavras:\n",
    "        if p in p_palavras:\n",
    "            prob += p_palavras[p]\n",
    "        if p in p_palavras:\n",
    "            prob_n += p_palavras[p]\n",
    "        if p not in lista_palavras:\n",
    "            log += math.log(1/4511, 10)\n",
    "        else:\n",
    "            log += math.log(p_palavras[p] + +1/4511, 10)\n",
    "    lista_result_num.append(log + math.log(172/300, 10))\n",
    "    if prob > prob_n:\n",
    "        return \"frase relevante\"\n",
    "    if prob <= prob_n:\n",
    "        return \"frase n relevante\"\n",
    "    return lista_result_num\n",
    "print(classificador(\"oi meu nome √© joao\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√£o √© relevante\n"
     ]
    }
   ],
   "source": [
    "def classificador_2(tweet):\n",
    "    palavras=tweet.split()\n",
    "    prob_r=1\n",
    "    prob_nr=1\n",
    "    g = tabela_tweets_relativar.sum()+len(lista_palavras)\n",
    "    z = tabela_tweets_relativa_n_rel.sum()+len(lista_palavras)\n",
    "    for p in palavras:\n",
    "        if p in tabela_tweets_relativar:\n",
    "            prob_r *= (tabela_tweets_relativar[p]+1) / g\n",
    "#             print(tabela_tweets_relativar[p])\n",
    "#             print(prob_r)\n",
    "#             print(g)\n",
    "        if p in tabela_tweets_relativa_n_rel:\n",
    "            prob_nr *= (tabela_tweets_relativa_n_rel[p]+1) / z\n",
    "#             print(tabela_tweets_relativa_n_rel[p])\n",
    "#             print(prob_nr)\n",
    "        else:\n",
    "            prob_nr *= 1 / z\n",
    "            prob_r *= 1 / g\n",
    "#             print(prob_nr)\n",
    "#             print(prob_r)\n",
    "    if prob_r > prob_nr:\n",
    "        return \"√â relevante\"\n",
    "    else: \n",
    "        return \"N√£o √© relevante\"\n",
    "print(classificador_2(\"gosto\"))\n",
    "# len(lista_palavras)+tabela_tweets_relativar.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hj eu peguei um snickers no veran e paguei',\n",
       " 's√≥ queria um snickers',\n",
       " 'q fome, t√¥ com um lanche natural de peito de peru no est√¥mago e um snickers',\n",
       " 'olukascastro üòßüòßüòßüòßüòß chocada snickers vc vai pagar a dentadura, amada',\n",
       " 'eu e as meninas acabamos de ganhar snickers de um cliente, amo üíï']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importando os testes e limpando\n",
    "tweets_tt_sujos = pd.read_excel(\"snickers.xlsx\", sheet_name = \"Teste\")\n",
    "teste = tweets_tt_sujos.loc[:, \"Teste\"]\n",
    "relt=tweets_tt_sujos.loc[:, \"Relev√¢ncia\"]\n",
    "tt_limpos1 = []\n",
    "tt_limpos2 = []\n",
    "tt_limpos = []\n",
    "for linhat in teste:\n",
    "    bt = linhat.lower()\n",
    "    tt_limpos1.append(cleanup(bt))\n",
    "for et in tt_limpos1:\n",
    "    a = et.strip()\n",
    "    tt_limpos2.append(a)\n",
    "for st in tt_limpos2:\n",
    "    z = ' '.join(st.split())\n",
    "    tt_limpos.append(z)\n",
    "tt_limpos[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n",
    "\n",
    "resultst=[add_space(text) for text in tt_limpos]\n",
    "lista_palavrast = []\n",
    "for pepe in resultst:\n",
    "    lista_palavrast += pepe.split()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "rando = pd.Series(resultst)\n",
    "dic={}\n",
    "for frase1 in rando:\n",
    "    resultado = classificador_2(frase1)\n",
    "    dic[frase1]=resultado\n",
    "# dic\n",
    "ir = 0\n",
    "inr = 0\n",
    "for k,v in dic.items():\n",
    "    if v == '√â relevante':\n",
    "        ir +=  1\n",
    "    elif v == 'N√£o √© relevante':\n",
    "        inr += 1\n",
    "print(inr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
